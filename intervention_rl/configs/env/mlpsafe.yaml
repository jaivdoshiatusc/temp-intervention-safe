defaults: 
    - base
    
# Environment-specific hyperparameters
name: 'SafetyRacecarGoal1-v0'
short_name: 'mlpsafe'
new_action: 0
catastrophe_clearance: 0
max_timesteps: 1000
n_envs: 16
n_stack: 4

# Blocker-related hyperparameters
bonus_type: 'catastrophe' # Choose from 'catastrophe', 'intervention', 'blocker'
alpha: 0.01  # Alpha coefficient for reward modification
alpha_increase: 0.01 # Increase in alpha coefficient
max_alpha: 500 # Maximum alpha coefficient
beta: 0.01   # Beta coefficient for reward modification
beta_increase: 0.01 # Increase in beta coefficient
max_beta: 500 # Maximum beta coefficient
iota: 0.05 # Iota coefficient for reward modification
penalty_type: 'none' # Choose from 'none', 'all', 'blocker'
penalty: -2 # Penalty for intervention

# Training hyperparameters
total_timesteps: 2500000          # Total training timesteps
log_freq: 20000                   # Log every log_freq timesteps
eval_freq: 20000                  # Evaluate every eval_freq timesteps
gif_freq: 100000                  # Generate gif every gif_freq timesteps
save_freq: 300000                 # Save model every save_freq timesteps

# Blocker-related hyperparameters
blocker_epochs: 4                 # Number of epochs to train the blocker
blocker_switch_time: 120000       # Timesteps before switching blocker behavior
blocker_train_freq: 20000         # Train blocker every blocker_train_freq timesteps
blocker_save_freq: 60000          # Save blocker model every blocker_save_freq timesteps